
// This file is autogenerated. DO NOT EDIT
#include <robotpy_build.h>




#include <frc/motorcontrol/Spark.h>








#define RPYGEN_ENABLE_frc__Spark_PROTECTED_CONSTRUCTORS
#include <rpygen/frc__Spark.hpp>







#include <wpi/sendable/SendableBuilder.h>



#include <type_traits>


  using namespace frc;





struct rpybuild_Spark_initializer {


  

  












  
  using Spark_Trampoline = rpygen::PyTrampoline_frc__Spark<typename frc::Spark, typename rpygen::PyTrampolineCfg_frc__Spark<>>;
    static_assert(std::is_abstract<Spark_Trampoline>::value == false, "frc::Spark " RPYBUILD_BAD_TRAMPOLINE);
  py::class_<typename frc::Spark, Spark_Trampoline, frc::PWMMotorController> cls_Spark;

    

    
    

  py::module &m;

  
  rpybuild_Spark_initializer(py::module &m) :

  

  

  

  
    cls_Spark(m, "Spark"),

  

  
  
  

    m(m)
  {
    
    

    
    
  

    
    
  }

void finish() {





  {
  
  
  


  

  cls_Spark.doc() =
    "REV Robotics SPARK Motor %Controller.\n"
"\n"
"Note that the SPARK uses the following bounds for PWM values. These values\n"
"should work reasonably well for most controllers, but if users experience\n"
"issues such as asymmetric behavior around the deadband or inability to\n"
"saturate the controller in either direction, calibration is recommended.\n"
"The calibration procedure can be found in the SPARK User Manual available\n"
"from REV Robotics.\n"
"\n"
"- 2.003ms = full \"forward\"\n"
"- 1.550ms = the \"high end\" of the deadband range\n"
"- 1.500ms = center of the deadband range (off)\n"
"- 1.460ms = the \"low end\" of the deadband range\n"
"- 0.999ms = full \"reverse\"";

  cls_Spark
  
    
  .def(py::init<int>(),
      py::arg("channel"), release_gil(), py::doc(
    "Constructor for a SPARK.\n"
"\n"
":param channel: The PWM channel that the SPARK is attached to. 0-9 are\n"
"                on-board, 10-19 are on the MXP port")
  )
  
  
  ;

  


  }






}

}; // struct rpybuild_Spark_initializer

static std::unique_ptr<rpybuild_Spark_initializer> cls;

void begin_init_Spark(py::module &m) {
  cls = std::make_unique<rpybuild_Spark_initializer>(m);
}

void finish_init_Spark() {
  cls->finish();
  cls.reset();
}